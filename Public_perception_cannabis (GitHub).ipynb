{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa83b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import date\n",
    "from matplotlib import pyplot as plt \n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib.dates import DateFormatter\n",
    "import seaborn as sns\n",
    "import tweepy\n",
    "from twitter_authentication import bearer_token\n",
    "import contractions\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from IPython.display import clear_output\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from bertopic import BERTopic\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da20a61",
   "metadata": {},
   "source": [
    "## Tweepy scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381abe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token, wait_on_rate_limit=True)\n",
    "start_time = ['2022-05-01T00:00:00Z']\n",
    "end_time = ['2022-06-13T23:59:59Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "\n",
    "for i,j in zip(start_time,end_time):\n",
    "    print(i)\n",
    "    print(j)\n",
    "    for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                     query = 'กัญชา -is:retweet lang:th',\n",
    "                                     #query = 'cannabis thailand OR weed thailand OR marijuana thailand OR pot thailand OR blunt thailand OR mary jane thailand -is:retweet lang:en',\n",
    "                                     user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                     tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                     expansions = ['author_id', 'geo.place_id'],\n",
    "                                     start_time = i,\n",
    "                                     end_time = j):\n",
    "                                     \n",
    "        time.sleep(1)\n",
    "        tweets.append(response)\n",
    "\n",
    "    result = []\n",
    "    user_dict = {}\n",
    "    for response in tweets:\n",
    "        for user in response.includes['users']:\n",
    "            user_dict[user.id] = {'username': user.username, \n",
    "                                  'followers': user.public_metrics['followers_count'],\n",
    "                                  'tweets': user.public_metrics['tweet_count'],\n",
    "                                  'description': user.description,\n",
    "                                  'location': user.location\n",
    "                                 }\n",
    "        for tweet in response.data:\n",
    "            author_info = user_dict[tweet.author_id]\n",
    "            result.append({'author_id': tweet.author_id,\n",
    "                           'geo.place_id': tweet.geo,\n",
    "                           'username': author_info['username'],\n",
    "                           'author_followers': author_info['followers'],\n",
    "                           'author_tweets': author_info['tweets'],\n",
    "                           'author_description': author_info['description'],\n",
    "                           'author_location': author_info['location'],\n",
    "                           'tweet': tweet.text,\n",
    "                           'created_at': tweet.created_at,\n",
    "                           'retweets': tweet.public_metrics['retweet_count'],\n",
    "                           'replies': tweet.public_metrics['reply_count'],\n",
    "                           'likes': tweet.public_metrics['like_count'],\n",
    "                           'quote_count': tweet.public_metrics['quote_count'],\n",
    "                            })\n",
    "    df = pd.DataFrame(result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e945010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('file_name.csv', index =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd808ef",
   "metadata": {},
   "source": [
    "## Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f64b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('file_name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f9b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using with eng\n",
    "df['processed']= df['tweet'].replace(r'http\\S+', ' ', regex=True)\n",
    "df['processed']=df['processed'].apply(contractions.fix)\n",
    "df['processed']=df['processed'].apply(lambda x :[t for t in x.split() if not t.startswith('@')] ).apply(lambda x: ' '.join(x))\n",
    "df['processed']= df['processed'].replace(r'[^A-Za-zก-๏]+', ' ', regex=True)\n",
    "df['processed']= df['processed'].replace(r'[ก-๙]+', ' ', regex=True)\n",
    "df['processed']=df['processed'].apply(lambda x : x.strip())\n",
    "df['processed']=df['processed'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab6336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using with eng after translate\n",
    "df['tr_processed']= df['translated'].replace(r'http\\S+', ' ', regex=True)\n",
    "df['tr_processed']=df['tr_processed'].apply(contractions.fix)\n",
    "df['tr_processed']=df['tr_processed'].apply(lambda x :[t for t in x.split() if not t.startswith('@')] ).apply(lambda x: ' '.join(x))\n",
    "df['tr_processed']= df['tr_processed'].replace(r'[^A-Za-zก-๏]+', ' ', regex=True)\n",
    "df['tr_processed']= df['tr_processed'].replace(r'[ก-๙]+', ' ', regex=True)\n",
    "df['tr_processed']=df['tr_processed'].apply(lambda x : x.strip())\n",
    "df['tr_processed']=df['tr_processed'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e6067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using with thai\n",
    "df['processed']= df['tweet'].replace(r'http\\S+', ' ', regex=True)\n",
    "df['processed']=df['processed'].apply(contractions.fix)\n",
    "df['processed']=df['processed'].apply(lambda x :[t for t in x.split() if not t.startswith('@')] ).apply(lambda x: ' '.join(x))\n",
    "df['processed']= df['processed'].replace(r'[^A-Za-zก-๏]+', ' ', regex=True)\n",
    "df['processed']= df['processed'].replace(r'[ๆ]+', ' ',regex=True)\n",
    "df['processed']=df['processed'].apply(lambda x : x.strip())\n",
    "df['processed']=df['processed'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate tweets\n",
    "df_unique = df.drop_duplicates(['choose_target_column'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee19eb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique.to_csv('file_name.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbff568c",
   "metadata": {},
   "source": [
    "## Translation-Thai --> English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8bc902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('file_name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fdfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from deep_translator import GoogleTranslator\n",
    "tweet_translated =[]\n",
    "for n in range(round(len(df))):\n",
    "    print(n)\n",
    "    clear_output(wait = True)\n",
    "    to_translate = df.processed[n]\n",
    "    translated = GoogleTranslator(source='auto', target='en').translate(to_translate)\n",
    "    tweet_translated.append(translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3281aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['translated'] = tweet_translated\n",
    "df.to_csv('file_name.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8258dabb",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8123a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('file_name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d430cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed'] = df['processed'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5190501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.processed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cce3836",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentAnalysis = pipeline(\"sentiment-analysis\")\n",
    "print(sentimentAnalysis(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793bd50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = []\n",
    "score = []\n",
    "for n in range(len(df)):\n",
    "    print(n)\n",
    "    clear_output(wait = True)\n",
    "    text = df.processed[n]\n",
    "    sentimentAnalysis = pipeline(\"sentiment-analysis\")\n",
    "    s = sentimentAnalysis(text)\n",
    "    s_sen = s[0]['label']\n",
    "    s_score = s[0]['score']\n",
    "    sentiment.append(s_sen)\n",
    "    score.append(s_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_transformer'] = sentiment\n",
    "df['transformer_score'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095dd662",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_sentiment'] = df.sentiment_transformer\n",
    "df.loc[df.transformer_score < 0.99, 'new_sentiment'] = 'NEUTRAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f2644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('file_name.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a0d77c",
   "metadata": {},
   "source": [
    "## Sort date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24c12ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('file_name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb37074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get before 2022-06-09 (1May2022-8June2022)\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "mask1 = (df['created_at'] > '2022-04-30T23:59:59Z') & (df['created_at'] <= '2022-06-08T23:59:59Z')\n",
    "df.loc[mask1]\n",
    "df_sort1 = df.loc[mask1]\n",
    "df_sort1.to_csv('file_name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd75b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get since 2022-06-09 (9June2022-13June2022)\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "mask1 = (df['created_at'] > '2022-06-08T23:59:59Z') & (df['created_at'] <= '2022-06-13T23:59:59Z')\n",
    "df.loc[mask1]\n",
    "df_sort1 = df.loc[mask1]\n",
    "df_sort1.to_csv('file_name.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4500b61d",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d13814",
   "metadata": {},
   "source": [
    "### Visualize number of tweets per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e0c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('file_name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f1675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "df_count = df['created_at'].groupby(df['created_at'].dt.date).count()\n",
    "df_count.columns = ['created_at','count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d776982",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count.to_csv('file_name.csv', header =['count'], index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de09b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"file_name.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555421b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['created_at'] = pd.to_datetime(data['created_at']).dt.date\n",
    "plt.plot(data['created_at'],data['count'],color='black')\n",
    "plt.setp(plt.gca().xaxis.get_majorticklabels(),rotation=90)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d-%b-%Y'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=3))\n",
    "plt.xlim([datetime.date(2022, 5, 1), datetime.date(2022, 6, 15)])\n",
    "plt.savefig('file_name.tiff', dpi=300, format='tiff', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14878668",
   "metadata": {},
   "source": [
    "### Visualize sentiment distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67464f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BF = pd.read_csv(\"file_name.csv\")\n",
    "BF = BF.groupby(\"new_sentiment\").sum()\n",
    "#BF.drop(['Unnamed: 0'], axis=1, inplace = True)\n",
    "BF = BF.reset_index()\n",
    "labels = BF['new_sentiment']\n",
    "count = BF['count']\n",
    "colors = (\"#CDCDCD\", \"#E5E5E5\", \"#A3A3A3\") \n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(count, labels=labels, autopct='%1.1f%%', textprops={'size': 'x-large'}, colors=colors)\n",
    "ax1.axis('equal')\n",
    "plt.title('title', pad=30)\n",
    "plt.savefig('file_name.tiff', dpi=300, format='tiff', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc54e19",
   "metadata": {},
   "source": [
    "### Stack bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20924403",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('file_name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119215bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set new index\n",
    "df.set_index(\"Category\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b08ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.div(df.sum(axis=1), axis=0)\n",
    "df = round(df*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df4b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(\"Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab16e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stacked bar chart\n",
    "ax = df.plot(kind='bar', stacked=True, cmap=\"tab20b\")\n",
    "\n",
    "# labels for x & y axis\n",
    "plt.xlabel('')\n",
    "plt.ylabel('ylabel')\n",
    "\n",
    "#reverse legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(reversed(handles),reversed(labels), loc=\"best\", ncol=1, bbox_to_anchor=(1, 0.5, 1, 0.5))\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# title of plot\n",
    "plt.title('name_of_title')\n",
    "plt.savefig('file_name.tiff', dpi=300, format='tiff',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09490f6",
   "metadata": {},
   "source": [
    "## Statistic calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d73730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BF = pd.read_csv(\"file_name.csv\")\n",
    "BF = BF.groupby(\"new_sentiment\").sum()\n",
    "BF.drop(['Unnamed: 0'], axis=1, inplace = True)\n",
    "BF = BF.reset_index()\n",
    "labels = BF['new_sentiment']\n",
    "cal = BF['count'].sum(axis = 0)\n",
    "print(cal)\n",
    "BF.to_csv('file_name.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8632306",
   "metadata": {},
   "outputs": [],
   "source": [
    "BF = pd.read_csv(\"file_name.csv\")\n",
    "AF = pd.read_csv(\"file_name.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03b8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "BF_T = BF.T\n",
    "BF_T = BF_T.rename(columns=BF_T.iloc[0]).drop(BF_T.index[0])\n",
    "AF_T = AF.T\n",
    "AF_T = AF_T.rename(columns=AF_T.iloc[0]).drop(AF_T.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f77fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi = pd.concat([BF_T,AF_T])\n",
    "c, p, dof, expected = chi2_contingency(chi) \n",
    "stat = (c,p,dof)\n",
    "chi_sq = pd.DataFrame([stat], columns =['chi-square','p-value','degrerOfreedom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2476e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sq.to_csv('file_name.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50bf6d7",
   "metadata": {},
   "source": [
    "## Topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae06b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('file_name.csv')\n",
    "doc = list(df.processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a31804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic()\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, \n",
    "                  min_dist=0.0, metric='cosine', random_state=42)\n",
    "topic_model = BERTopic(umap_model=umap_model, top_n_words = 15)\n",
    "topics, probs = topic_model.fit_transform(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3757310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info = topic_model.get_topic_info()\n",
    "topic_info.to_csv('file_name.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info_result = topic_model.get_topics()\n",
    "topic_info_result_df = pd.DataFrame.from_dict(topic_info_result)\n",
    "topic_info_result_df.to_csv('file_name.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c55015",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_representative_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd6751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_table = topic_model.get_representative_docs()\n",
    "topic_tab = pd.DataFrame(topic_table)\n",
    "topic_tab.columns = ['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14612336",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_tab.to_csv('file_name.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python38]",
   "language": "python",
   "name": "conda-env-python38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
